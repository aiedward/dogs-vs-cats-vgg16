{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在開始之前, 先從 Kaggle 下載訓練以及測試用的資料:\n",
    "\n",
    "```\n",
    "kg download -u `user_name` -p `password` -c dogs-vs-cats-redux-kernels-edition\n",
    "```\n",
    "\n",
    "不過在下載之前, 必須先到 Kaggle 註冊帳號, 以及同意 Competition 的規則才能下載檔案:\n",
    "https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition\n",
    "\n",
    "Todo:\n",
    "1. 設立 Sample 與 Valid data set 目錄\n",
    "2. 將 Kaggle 的檔案放置到符合 Keras 的目錄結構下\n",
    "3. 載入 VGG16 model, finetune 以及重新對 dogs & cats 作訓練\n",
    "4. 預測 Kaggle 的 test set\n",
    "5. 驗證測試結果\n",
    "6. 在 Kaggle 上送交結果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 設立 Sample 與 Valid data set 目錄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%pwd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/paperspace/src/fastai/deeplearning_keras2/steven/data/redux'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys\n",
    "current_dir = os.getcwd()\n",
    "ROOT_PATH = current_dir\n",
    "DATA_HOME_PATH = current_dir + '/data/redux'\n",
    "DATA_HOME_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd $DATA_HOME_PATH\n",
    "%mkdir valid\n",
    "%mkdir results\n",
    "%mkdir sample\n",
    "%mkdir -p sample/valid\n",
    "%mkdir -p sample/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/paperspace/src/fastai/deeplearning_keras2/steven/data/redux/train\n"
     ]
    }
   ],
   "source": [
    "# 準備驗證資料\n",
    "\n",
    "%cd $DATA_HOME_PATH/train\n",
    "all_training_files = glob(\"*.jpg\")\n",
    "\n",
    "# 打亂檔案列表\n",
    "shuffles = np.random.permutation(all_training_files)\n",
    "if len(shuffles) > 0:\n",
    "    # 取其中 2000 個檔案作為驗證資料用\n",
    "    for i in range(0, 2000):\n",
    "        os.rename(shuffles[i], DATA_HOME_PATH + '/valid/' + shuffles[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 為解省開發上時間的耗費, 會建立一個資料量相對小的 Sample 目錄, 程式開發完之後再轉移到完整的資料上\n",
    "# 準備 Sample 的 training 資料\n",
    "%cd $DATA_HOME_PATH/train\n",
    "all_training_files = glob(\"*.jpg\")\n",
    "\n",
    "# 打亂檔案列表\n",
    "shuffles = np.random.permutation(all_training_files)\n",
    "if len(shuffles) > 0:\n",
    "    # 取其中 200 個作為 Sample 的訓練資料\n",
    "    for i in range(0, 200):\n",
    "        copyfile(shuffles[i], DATA_HOME_PATH + '/sample/train/' + shuffles[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 準備 Sample 的 Valid 資料\n",
    "%cd $DATA_HOME_PATH/valid\n",
    "\n",
    "all_valid_files = glob(\"*.jpg\")\n",
    "shuffles = np.random.permutation(all_valid_files)\n",
    "if len(shuffles) > 0:\n",
    "    # 拿其中 50 個檔案作為 Sample 的驗證資料\n",
    "    for i in range(0, 50):\n",
    "        copyfile(shuffles[i], DATA_HOME_PATH + '/sample/valid/' + shuffles[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 將 Kaggle 的檔案放置到符合 Keras 的目錄結構下\n",
    "\n",
    "Keras 的目錄結構用「類別」名稱作來命名子目錄, 從 Kaggle 下載下來的檔案則是用檔名的區分, 例如 cats.3111.jpg, 所以在這個步驟我們要建立 cats 跟 dogs 子目錄, 並將這些圖檔搬移到相對應的子目錄裡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd $DATA_HOME_PATH/train\n",
    "%mkdir cats\n",
    "%mkdir dogs\n",
    "%mv cat.*.jpg cats/\n",
    "%mv dog.*.jpg dogs/\n",
    "\n",
    "%cd $DATA_HOME_PATH/valid\n",
    "%mkdir cats\n",
    "%mkdir dogs\n",
    "%mv cat.*.jpg cats/\n",
    "%mv dog.*.jpg dogs/\n",
    "\n",
    "%cd $DATA_HOME_PATH/sample/train\n",
    "%mkdir cats\n",
    "%mkdir dogs\n",
    "%mv cat.*.jpg cats/\n",
    "%mv dog.*.jpg dogs/\n",
    "\n",
    "%cd $DATA_HOME_PATH/sample/valid\n",
    "%mkdir cats\n",
    "%mkdir dogs\n",
    "%mv cat.*.jpg cats/\n",
    "%mv dog.*.jpg dogs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd $DATA_HOME_PATH/test\n",
    "%mkdir unknown\n",
    "%mv *.jpg unknown/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 載入 VGG16 model, finetune 以及重新對 dogs & cats 作訓練\n",
    "\n",
    "VGG16 是 Visual Geometry Group 的縮寫, 通常有分作 16 層跟 19 層 Neuon Network 的兩種版本, 它可以辨識 ImageNet 中 1500 個影像類別, 是個十分強大的 CNN 演算法, 網路上也可以下載到 pre-trained 的 model, 省下一開始找資料以及 training 上的時間, 可以直接拿來應用\n",
    "\n",
    "這裡用的 VGG16 是直接拿 fast.ai 的實作版本, 這個實作版本與 fast.ai github 上的版本不同, 採用 Python3 跟 Keras2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/paperspace/src/fastai/deeplearning_keras2/steven\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%cd $ROOT_PATH\n",
    "\n",
    "from vgg16 import Vgg16\n",
    "\n",
    "path = DATA_HOME_PATH + '/sample/'\n",
    "valid_path = path + '/valid/'\n",
    "train_path = path + '/train/'\n",
    "test_path = DATA_HOME_PATH + '/test/'\n",
    "result_path = DATA_HOME_PATH + '/results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 初始化 vgg 物件, 第一次初始會下載 Vgg16 pre-trained 的 weights, 下載檔案會放在 ~/.keras/models/\n",
    "vgg = Vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "epoch_num = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "原本 Vgg16 model 可以偵測 1500 種類別, 但是在這裡我們只有兩種類別, 所以透過 Keras 的 finetune 機制將原本的 model mapping 到這兩種類別上\n",
    "\n",
    "get_batches 會使用 Keras API - [Image Preprocessing](https://keras.io/preprocessing/image/), 從指定的目錄中批次將圖片讀出, 並對圖片作正規化, 每張圖片縮放成 244x244 大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batches = vgg.get_batches(train_path, batch_size=batch_size)\n",
    "vgg.finetune(batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下來, 我們可以跑幾個 epoch 來 retrain model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "50/50 [==============================] - 9s - loss: 0.7724 - acc: 0.7600 - val_loss: 0.7335 - val_acc: 0.7600\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 5s - loss: 0.3012 - acc: 0.8950 - val_loss: 0.6426 - val_acc: 0.7800\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 5s - loss: 0.3682 - acc: 0.9250 - val_loss: 0.6923 - val_acc: 0.8200\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 5s - loss: 0.1478 - acc: 0.9400 - val_loss: 0.6790 - val_acc: 0.8400\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 5s - loss: 0.1331 - acc: 0.9400 - val_loss: 0.7952 - val_acc: 0.8600\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 5s - loss: 0.1250 - acc: 0.9400 - val_loss: 0.4921 - val_acc: 0.8400\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 5s - loss: 0.1255 - acc: 0.9600 - val_loss: 0.8544 - val_acc: 0.7600\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 5s - loss: 0.1243 - acc: 0.9450 - val_loss: 0.7495 - val_acc: 0.8800\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 5s - loss: 0.0918 - acc: 0.9550 - val_loss: 0.8179 - val_acc: 0.8400\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 5s - loss: 0.0767 - acc: 0.9650 - val_loss: 1.2132 - val_acc: 0.8200\n"
     ]
    }
   ],
   "source": [
    "val_batches = vgg.get_batches(valid_path, batch_size=batch_size)\n",
    "vgg.fit(batches, val_batches, batch_size, nb_epoch=epoch_num)\n",
    "latest_weights_filename = 'ft%d.h5'\n",
    "vgg.model.save_weights(result_path + latest_weights_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12500 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "batches, preds = vgg.test(test_path, batch_size=batch_size)\n",
    "preds[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
